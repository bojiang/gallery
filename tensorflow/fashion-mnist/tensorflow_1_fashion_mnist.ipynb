{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jYysdyb-CaWM"
   },
   "source": [
    "# Basic classification: Classify images of clothing\n",
    "A tensorflow serving style service example using BentoML\n",
    "\n",
    "\n",
    "![Impression](https://www.google-analytics.com/collect?v=1&tid=UA-112879361-3&cid=555&t=event&ec=tensorflow&ea=tensorflow_1_fashion_mnist&dt=tensorflow_1_fashion_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q bentoml tensorflow==1.14.0 matplotlib \"numpy<1.17\"\n",
    "# why numpy<1.17: https://github.com/tensorflow/tensorflow/issues/30427"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dzLKpmZICaWN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import io\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7MqDQO0KCaWS"
   },
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(_train_images, train_labels), (_test_images, test_labels) = fashion_mnist.load_data()\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "train_images = _train_images / 255.0\n",
    "test_images = _test_images / 255.0\n",
    "\n",
    "train_x = np.reshape(train_images, [-1, 28, 28, 1])\n",
    "train_y = np.eye(10)[train_labels]  # one hot\n",
    "\n",
    "test_x = np.reshape(test_images, [-1, 28, 28, 1])\n",
    "test_y = np.eye(10)[test_labels]  # one hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [None, 28, 28, 1]\n",
    "number_of_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function below builds model graph \n",
    "def cnn_model_fn(input_shape, number_of_classes, learning_rate):\n",
    "    raw = tf.placeholder(tf.string, shape=[None])\n",
    "    with tf.device(\"/cpu:0\"): # map_fn has issues on GPU https://github.com/tensorflow/tensorflow/issues/28007\n",
    "        img_array = tf.map_fn(lambda i: tf.io.decode_png(i, channels=1), raw, dtype=tf.uint8)\n",
    "    img_array = tf.cast(img_array, tf.float32)\n",
    "    img_array = (255.0 - img_array) / 255.0\n",
    "    \n",
    "    input_layer = tf.reshape(img_array, [-1, 28, 28, 1])\n",
    "\n",
    "    #input_layer = tf.placeholder(tf.float32, shape=input_shape)\n",
    "    labels = tf.placeholder(tf.float32, shape=[None, number_of_classes])\n",
    "    \n",
    "    #Train mode is used with dropout layers. We want effectively disable the dropout layers while\n",
    "    #evaluation and predict and use it only while training\n",
    "    train_mode = tf.placeholder(tf.bool)\n",
    "    \n",
    "    #Architecture: image ->conv2d->maxpooling->conv2d->maxpooling->flatten->dense->dropout->logits->softmax\n",
    "    \n",
    "    #convolution layer 1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer, \n",
    "        filters=32, \n",
    "        kernel_size=[5, 5], \n",
    "        padding=\"same\", \n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    #pooling layer 1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    #convolution layer 2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1, \n",
    "        filters=64, \n",
    "        kernel_size=[5, 5], \n",
    "        padding=\"same\", \n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    #pooling layer 1\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    #flatten the output volume of pool2 into a vector\n",
    "    pool2_flat = tf.reshape(pool2, shape=[-1, 7*7*64])\n",
    "    \n",
    "    #dense layer\n",
    "    dense = tf.layers.dense(\n",
    "        inputs=pool2_flat, \n",
    "        units=1024,\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    #dropout regularization\n",
    "    dropout = tf.layers.dropout(\n",
    "        inputs=dense, \n",
    "        rate=0.3, \n",
    "        training= train_mode)\n",
    "    \n",
    "    #logits layer\n",
    "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "    \n",
    "    predictions = {\n",
    "        \"classes\" : tf.argmax(input=logits, axis=1),\n",
    "        \"probabilities\" : tf.nn.softmax(logits=logits)\n",
    "    }\n",
    "    \n",
    "    #loss\n",
    "    loss = tf.losses.softmax_cross_entropy(labels, logits)\n",
    "    \n",
    "    #training operartion\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "    \n",
    "    #accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1)), tf.float32))\n",
    "    \n",
    "    return { \"logits\": logits,\n",
    "             \"predictions\": predictions,\n",
    "             \"loss\": loss,\n",
    "             \"train_op\": train_op,\n",
    "             \"accuracy\": accuracy,\n",
    "             \"raw_x\": raw,\n",
    "             \"x\": input_layer,\n",
    "             \"y\": labels,\n",
    "             \"train_mode\": train_mode }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-ea64c7cb57cc>:26: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From /opt/conda/envs/bentoml-py3_6-tf1_4/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb049fac390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb049fac390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb049fac390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb049fac390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From <ipython-input-4-ea64c7cb57cc>:29: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb049fac390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb049fac390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb049fac390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb049fac390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb049fac390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb049fac390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb049fac390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb049fac390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb049fac390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb049fac390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb049fac390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb049fac390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From <ipython-input-4-ea64c7cb57cc>:49: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb044d5ba90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb044d5ba90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb044d5ba90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb044d5ba90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From <ipython-input-4-ea64c7cb57cc>:55: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb044d5ba90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb044d5ba90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb044d5ba90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb044d5ba90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb044d5ba90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb044d5ba90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb044d5ba90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb044d5ba90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /opt/conda/envs/bentoml-py3_6-tf1_4/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "batch_size = 1000\n",
    "epoch = 5\n",
    "\n",
    "tf.reset_default_graph()\n",
    "cnn_model = cnn_model_fn(input_shape, number_of_classes, learning_rate)\n",
    "x = cnn_model[\"x\"]\n",
    "y= cnn_model[\"y\"]\n",
    "train_mode = cnn_model[\"train_mode\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ODch-OFCaW4"
   },
   "source": [
    "## Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:Start\n",
      "Epoch 1:\n",
      "############################################################\n",
      "loss: 0.86 accuracy: 0.75 \n",
      "val_loss: 0.40 val_accuracy: 0.85\n",
      "Epoch 2:\n",
      "############################################################\n",
      "loss: 0.35 accuracy: 0.88 \n",
      "val_loss: 0.32 val_accuracy: 0.88\n",
      "Epoch 3:\n",
      "############################################################\n",
      "loss: 0.29 accuracy: 0.90 \n",
      "val_loss: 0.29 val_accuracy: 0.89\n",
      "Epoch 4:\n",
      "############################################################\n",
      "loss: 0.26 accuracy: 0.91 \n",
      "val_loss: 0.27 val_accuracy: 0.90\n",
      "Epoch 5:\n",
      "############################################################\n",
      "loss: 0.24 accuracy: 0.92 \n",
      "val_loss: 0.28 val_accuracy: 0.90\n",
      "Training:End\n",
      "Test accuracy 0.90\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: test_model/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    with tf.device(\"/gpu:0\"):\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        #Divide input training set into mini batches of size batch_size.\n",
    "        #If the total number of training examles is not exactly divisible by batch_size, \n",
    "        #the last batch will have less number of examples than batch_size.\n",
    "\n",
    "        total_size = train_x.shape[0]\n",
    "        number_of_batches = int(total_size/batch_size)\n",
    "\n",
    "        print(\"Training:Start\")\n",
    "        for e in range(epoch):\n",
    "            epoch_cost = 0\n",
    "            epoch_accuracy = 0\n",
    "            print(\"Epoch {}:\".format(e+1))\n",
    "            for i in range(number_of_batches):\n",
    "                print(\"#\", end='')\n",
    "                mini_x = train_x[i*batch_size:(i+1)*batch_size, :, :, :]\n",
    "                mini_y = train_y[i*batch_size:(i+1)*batch_size, :]\n",
    "                _, cost = sess.run([cnn_model[\"train_op\"], cnn_model[\"loss\"]], \n",
    "                    feed_dict={x:mini_x, \n",
    "                               y:mini_y,\n",
    "                               train_mode:True})\n",
    "                train_accuracy = sess.run(cnn_model[\"accuracy\"], \n",
    "                    feed_dict={x:mini_x, \n",
    "                               y:mini_y,\n",
    "                               train_mode:False})\n",
    "                epoch_cost += cost\n",
    "                epoch_accuracy += train_accuracy\n",
    "\n",
    "            #If the total number of training examles is not exactly divisible by batch_size, \n",
    "            #we have one more batch of size (total_size - number_of_batches*batch_size)\n",
    "            if total_size % batch_size != 0:\n",
    "                print(\"#\", end='')\n",
    "                mini_x = train_x[number_of_batches*batch_size:total_size, :, :, :]\n",
    "                mini_y = train_y[number_of_batches*batch_size:total_size, :]\n",
    "                _, cost = sess.run([cnn_model[\"train_op\"], cnn_model[\"loss\"]], \n",
    "                    feed_dict={x:mini_x, \n",
    "                               y:mini_y,\n",
    "                               train_mode:True})\n",
    "                train_accuracy = sess.run(cnn_model[\"accuracy\"], \n",
    "                    feed_dict={x:mini_x, \n",
    "                               y:mini_y,\n",
    "                               train_mode: False})\n",
    "                epoch_cost += cost\n",
    "                epoch_accuracy += train_accuracy\n",
    "\n",
    "            epoch_cost /= number_of_batches\n",
    "\n",
    "            if total_size % batch_size != 0:\n",
    "                epoch_accuracy /= (number_of_batches+1)\n",
    "            else:\n",
    "                epoch_accuracy /= number_of_batches\n",
    "            print()    \n",
    "            print(\"loss: {:02.2f} accuracy: {:02.2f} \".format(np.squeeze(epoch_cost), epoch_accuracy))\n",
    "            #Cross validation loss and accuracy\n",
    "            cv_loss, cv_accuracy = sess.run([cnn_model[\"loss\"], cnn_model[\"accuracy\"]], \n",
    "                                        {x:test_x, \n",
    "                                         y:test_y,\n",
    "                                         train_mode: False})\n",
    "            print(\"val_loss: {:02.2f} val_accuracy: {:02.2f}\".format(np.squeeze(cv_loss), cv_accuracy))\n",
    "\n",
    "        print(\"Training:End\")\n",
    "\n",
    "\n",
    "        #prediction for test set\n",
    "        test_accuracy, prediction = sess.run([cnn_model[\"accuracy\"], \n",
    "                                              cnn_model[\"predictions\"][\"classes\"]], \n",
    "                                             {x:test_x, y:test_y, train_mode:False})\n",
    "        print(\"Test accuracy {:02.2f}\".format(test_accuracy))\n",
    "\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        inputs = {\"x\":cnn_model['raw_x'], \"train_mode\":cnn_model['train_mode']}\n",
    "        outputs = {\"prediction\": cnn_model['predictions']['classes']}\n",
    "        tf.saved_model.simple_save(sess, 'test_model', inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model inference test run (Ipython kernel restarting required!!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "with open(\"test.png\", \"rb\") as f:\n",
    "    img_bytes = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ankle boot']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "\n",
    "loaded = tf.compat.v2.saved_model.load('test_model')\n",
    "loaded_func = loaded.signatures[tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "pred = loaded_func(x=tf.constant([img_bytes], dtype=tf.string), train_mode=tf.constant(False))\n",
    "output = pred['prediction']\n",
    "[class_names[c] for c in output]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YFc2HbEVCaXd"
   },
   "source": [
    "And the model predicts a label as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create BentoService class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tensorflow_1_fashion_mnist.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tensorflow_1_fashion_mnist.py\n",
    "\n",
    "import bentoml\n",
    "import tensorflow as tf\n",
    "\n",
    "from bentoml.frameworks.tensorflow import TensorflowSavedModelArtifact\n",
    "from bentoml.adapters import TfTensorInput\n",
    "\n",
    "tf.compat.v1.enable_eager_execution() # required\n",
    "\n",
    "FASHION_MNIST_CLASSES = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "\n",
    "@bentoml.env(pip_dependencies=['tensorflow', 'numpy', 'pillow'])\n",
    "@bentoml.artifacts([TensorflowSavedModelArtifact('trackable')])\n",
    "class FashionMnistTensorflow(bentoml.BentoService):\n",
    "\n",
    "    @bentoml.api(input=TfTensorInput(), batch=True)\n",
    "    def predict(self, inputs):\n",
    "        loaded_func = self.artifacts.trackable.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "        pred = loaded_func(x=inputs, train_mode=tf.constant(False))\n",
    "        output = pred['prediction']\n",
    "        return [FASHION_MNIST_CLASSES[c] for c in output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-09-23 02:36:48,284] WARNING - pip package requirement tensorflow already exist\n",
      "[2020-09-23 02:37:08,468] INFO - Detected non-PyPI-released BentoML installed, copying local BentoML modulefiles to target saved bundle path..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/bentoml-py3_6-tf1_4/lib/python3.6/site-packages/setuptools/dist.py:452: UserWarning: Normalizing '0.9.0.pre+7.g8af1c8b' to '0.9.0rc0+7.g8af1c8b'\n",
      "  if version != normalized:\n",
      "warning: no previously-included files matching '*~' found anywhere in distribution\n",
      "warning: no previously-included files matching '*.pyo' found anywhere in distribution\n",
      "warning: no previously-included files matching '.git' found anywhere in distribution\n",
      "warning: no previously-included files matching '.ipynb_checkpoints' found anywhere in distribution\n",
      "warning: no previously-included files matching '__pycache__' found anywhere in distribution\n",
      "warning: no directories found matching 'bentoml/yatai/web/dist'\n",
      "no previously-included directories found matching 'e2e_tests'\n",
      "no previously-included directories found matching 'tests'\n",
      "no previously-included directories found matching 'benchmark'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDATING BentoML-0.9.0rc0+7.g8af1c8b/bentoml/_version.py\n",
      "set BentoML-0.9.0rc0+7.g8af1c8b/bentoml/_version.py to '0.9.0.pre+7.g8af1c8b'\n",
      "[2020-09-23 02:37:09,283] INFO - BentoService bundle 'FashionMnistTensorflow:20200923023648_D5975E' saved to: /home/bentoml/bentoml/repository/FashionMnistTensorflow/20200923023648_D5975E\n"
     ]
    }
   ],
   "source": [
    "from tensorflow_1_fashion_mnist import FashionMnistTensorflow\n",
    "\n",
    "bento_svc = FashionMnistTensorflow()\n",
    "bento_svc.pack(\"trackable\", \"test_model/\")\n",
    "saved_path = bento_svc.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use BentoService with BentoML CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`bentoml get <BentoService Name>` list all of BentoService's versions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[39mBENTO_SERVICE                                 AGE           APIS                                  ARTIFACTS                                LABELS\n",
      "FashionMnistTensorflow:20200923023648_D5975E  7.73 seconds  predict<TfTensorInput:DefaultOutput>  trackable<TensorflowSavedModelArtifact>\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!bentoml get FashionMnistTensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`bentoml get <BentoService name>:<bentoService version>` display detailed information of the specific BentoService version**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-09-23 02:37:28,334] INFO - Getting latest version FashionMnistTensorflow:20200923023648_D5975E\n",
      "\u001b[39m{\n",
      "  \"name\": \"FashionMnistTensorflow\",\n",
      "  \"version\": \"20200923023648_D5975E\",\n",
      "  \"uri\": {\n",
      "    \"type\": \"LOCAL\",\n",
      "    \"uri\": \"/home/bentoml/bentoml/repository/FashionMnistTensorflow/20200923023648_D5975E\"\n",
      "  },\n",
      "  \"bentoServiceMetadata\": {\n",
      "    \"name\": \"FashionMnistTensorflow\",\n",
      "    \"version\": \"20200923023648_D5975E\",\n",
      "    \"createdAt\": \"2020-09-22T18:37:09.233305Z\",\n",
      "    \"env\": {\n",
      "      \"condaEnv\": \"name: bentoml-default-conda-env\\nchannels:\\n- conda-forge\\n- defaults\\ndependencies:\\n- pip\\n\",\n",
      "      \"pythonVersion\": \"3.6.10\",\n",
      "      \"dockerBaseImage\": \"bentoml/model-server:0.9.0.pre-py36\",\n",
      "      \"pipPackages\": [\n",
      "        \"bentoml==0.9.0.pre\",\n",
      "        \"tensorflow==1.14.0\",\n",
      "        \"numpy==1.16.6\",\n",
      "        \"pillow==7.2.0\"\n",
      "      ]\n",
      "    },\n",
      "    \"artifacts\": [\n",
      "      {\n",
      "        \"name\": \"trackable\",\n",
      "        \"artifactType\": \"TensorflowSavedModelArtifact\"\n",
      "      }\n",
      "    ],\n",
      "    \"apis\": [\n",
      "      {\n",
      "        \"name\": \"predict\",\n",
      "        \"inputType\": \"TfTensorInput\",\n",
      "        \"docs\": \"BentoService inference API 'predict', input: 'TfTensorInput', output: 'DefaultOutput'\",\n",
      "        \"inputConfig\": {\n",
      "          \"method\": \"predict\"\n",
      "        },\n",
      "        \"outputConfig\": {\n",
      "          \"cors\": \"*\"\n",
      "        },\n",
      "        \"outputType\": \"DefaultOutput\",\n",
      "        \"mbMaxLatency\": 10000,\n",
      "        \"mbMaxBatchSize\": 2000,\n",
      "        \"batch\": true\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!bentoml get FashionMnistTensorflow:latest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Serve bentoml REST server locally**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-09-23 02:38:47,885] INFO - Getting latest version FashionMnistTensorflow:20200923023648_D5975E\n",
      "[2020-09-23 02:38:47,886] INFO - Starting BentoML API server in development mode..\n",
      "[2020-09-23 02:38:49,034] WARNING - Using BentoML installed in `editable` model, the local BentoML repository including all code changes will be packaged together with saved bundle created, under the './bundled_pip_dependencies' directory of the saved bundle.\n",
      "[2020-09-23 02:38:49,049] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.9.0.pre, but loading from BentoML version 0.9.0.pre+7.g8af1c8b\n",
      "/opt/anaconda3/envs/bentoml-py3_6-tf1_4/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/envs/bentoml-py3_6-tf1_4/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/envs/bentoml-py3_6-tf1_4/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/envs/bentoml-py3_6-tf1_4/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/envs/bentoml-py3_6-tf1_4/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/envs/bentoml-py3_6-tf1_4/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/anaconda3/envs/bentoml-py3_6-tf1_4/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/envs/bentoml-py3_6-tf1_4/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/envs/bentoml-py3_6-tf1_4/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/envs/bentoml-py3_6-tf1_4/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/envs/bentoml-py3_6-tf1_4/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/envs/bentoml-py3_6-tf1_4/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "2020-09-23 02:38:50.293801: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
      "2020-09-23 02:38:50.308955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-09-23 02:38:50.309315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.6705\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-09-23 02:38:50.309476: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-09-23 02:38:50.310925: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10\n",
      "2020-09-23 02:38:50.312201: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10\n",
      "2020-09-23 02:38:50.312440: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10\n",
      "2020-09-23 02:38:50.313965: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-09-23 02:38:50.314916: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-09-23 02:38:50.318372: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-09-23 02:38:50.318538: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-09-23 02:38:50.318965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-09-23 02:38:50.319299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2020-09-23 02:38:50.319551: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-09-23 02:38:50.483503: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-09-23 02:38:50.483944: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561ae8d47940 executing computations on platform CUDA. Devices:\n",
      "2020-09-23 02:38:50.483964: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1060, Compute Capability 6.1\n",
      "2020-09-23 02:38:50.484140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-09-23 02:38:50.484539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.6705\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-09-23 02:38:50.484588: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-09-23 02:38:50.484602: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10\n",
      "2020-09-23 02:38:50.484616: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10\n",
      "2020-09-23 02:38:50.484629: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10\n",
      "2020-09-23 02:38:50.484642: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-09-23 02:38:50.484655: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-09-23 02:38:50.484668: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-09-23 02:38:50.484730: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-09-23 02:38:50.485093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-09-23 02:38:50.485429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2020-09-23 02:38:50.485470: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-09-23 02:38:50.485930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-09-23 02:38:50.485944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2020-09-23 02:38:50.485964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2020-09-23 02:38:50.486049: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-09-23 02:38:50.486415: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-09-23 02:38:50.486767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5683 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "2020-09-23 02:38:50.508981: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2699905000 Hz\n",
      "2020-09-23 02:38:50.509408: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561aec4be5e0 executing computations on platform Host. Devices:\n",
      "2020-09-23 02:38:50.509433: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "[2020-09-23 02:38:50,717] WARNING - Importing SavedModels from TensorFlow 1.x.\n",
      "                `outputs = imported(inputs)` is not supported in bento service due to\n",
      "                tensorflow API.\n",
      "\n",
      "                Recommended usage:\n",
      "\n",
      "                ```python\n",
      "                from tensorflow.python.saved_model import signature_constants\n",
      "\n",
      "                imported = tf.saved_model.load(path_to_v1_saved_model)\n",
      "                wrapped_function = imported.signatures[\n",
      "                    signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
      "                wrapped_function(tf.ones([]))\n",
      "                ```\n",
      "\n",
      "                See https://www.tensorflow.org/api_docs/python/tf/saved_model/load for\n",
      "                details.\n",
      "                \n",
      "[2020-09-23 02:38:50,718] WARNING - pip package requirement tensorflow already exist\n",
      " * Serving Flask app \"FashionMnistTensorflow\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n",
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!bentoml serve FashionMnistTensorflow:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query REST API with python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: {\"instances\": [{\"b64\": \"iVBORw0KGgoAAAANSUhEUgAAAB ... ufkz8DPG//sD/AX8I8DvdgnOxdB4B1wAAAAASUVORK5CYII=\"}]}\n",
      "<Response [200]>\n",
      "[\"Ankle boot\"]\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import json\n",
    "import requests\n",
    "\n",
    "with open(\"test.png\", \"rb\") as f:\n",
    "    img_bytes = f.read()\n",
    "img_b64 = base64.b64encode(img_bytes).decode()\n",
    "\n",
    "\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "data = json.dumps(\n",
    "       {\"instances\": [{\"b64\": img_b64}]}\n",
    ")\n",
    "print('Data: {} ... {}'.format(data[:50], data[len(data)-52:]))\n",
    "\n",
    "json_response = requests.post(f'http://localhost:5000/predict', data=data, headers=headers)\n",
    "print(json_response)\n",
    "print(json_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build realtime prediction service in docker with BentoService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-09-23 02:48:05,458] INFO - Getting latest version FashionMnistTensorflow:20200923023648_D5975E\n",
      "\u001b[39mFound Bento: /home/bentoml/bentoml/repository/FashionMnistTensorflow/20200923023648_D5975E\u001b[0m\n",
      "[2020-09-23 02:48:05,477] WARNING - Using BentoML installed in `editable` model, the local BentoML repository including all code changes will be packaged together with saved bundle created, under the './bundled_pip_dependencies' directory of the saved bundle.\n",
      "[2020-09-23 02:48:05,491] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.9.0.pre, but loading from BentoML version 0.9.0.pre+7.g8af1c8b\n",
      "Building Docker image fashionmnisttensorflow:latest from FashionMnistTensorflow:latest \n",
      "|\u001b[39mStep 1/15 : FROM bentoml/model-server:0.9.0.pre-py36\u001b[0m\n",
      "\u001b[39m ---> 4aac43d10e50\u001b[0m\n",
      "\u001b[39mStep 2/15 : ARG EXTRA_PIP_INSTALL_ARGS=\u001b[0m\n",
      "\u001b[39m ---> Using cache\u001b[0m\n",
      "\u001b[39m ---> 790054f5ad85\u001b[0m\n",
      "\u001b[39mStep 3/15 : ENV EXTRA_PIP_INSTALL_ARGS $EXTRA_PIP_INSTALL_ARGS\u001b[0m\n",
      "\u001b[39m ---> Using cache\u001b[0m\n",
      "\u001b[39m ---> 85b0a1b40542\u001b[0m\n",
      "\u001b[39mStep 4/15 : COPY environment.yml requirements.txt setup.sh* bentoml-init.sh python_version* /bento/\u001b[0m\n",
      "\u001b[39m ---> Using cache\u001b[0m\n",
      "\u001b[39m ---> 416fc81180f3\u001b[0m\n",
      "\u001b[39mStep 5/15 : WORKDIR /bento\u001b[0m\n",
      "\u001b[39m ---> Using cache\u001b[0m\n",
      "\u001b[39m ---> 02b613c56380\u001b[0m\n",
      "\u001b[39mStep 6/15 : RUN chmod +x /bento/bentoml-init.sh\u001b[0m\n",
      "\u001b[39m ---> Using cache\u001b[0m\n",
      "\u001b[39m ---> 6a6ef17c3452\u001b[0m\n",
      "\u001b[39mStep 7/15 : RUN if [ -f /bento/bentoml-init.sh ]; then bash -c /bento/bentoml-init.sh; fi\u001b[0m\n",
      "\u001b[39m ---> Using cache\u001b[0m\n",
      "\u001b[39m ---> ce00ce7aa402\u001b[0m\n",
      "\u001b[39mStep 8/15 : COPY . /bento\u001b[0m\n",
      "\u001b[39m ---> Using cache\u001b[0m\n",
      "\u001b[39m ---> d5ca506d96d8\u001b[0m\n",
      "\u001b[39mStep 9/15 : RUN if [ -d /bento/bundled_pip_dependencies ]; then pip install -U bundled_pip_dependencies/* ;fi\u001b[0m\n",
      "\u001b[39m ---> Using cache\u001b[0m\n",
      "\u001b[39m ---> 3e39345c79a4\u001b[0m\n",
      "\u001b[39mStep 10/15 : ENV PORT 5000\u001b[0m\n",
      "\u001b[39m ---> Using cache\u001b[0m\n",
      "\u001b[39m ---> 091da99a4974\u001b[0m\n",
      "\u001b[39mStep 11/15 : EXPOSE $PORT\u001b[0m\n",
      "\u001b[39m ---> Using cache\u001b[0m\n",
      "\u001b[39m ---> 70d396a81a41\u001b[0m\n",
      "\u001b[39mStep 12/15 : COPY docker-entrypoint.sh /usr/local/bin/\u001b[0m\n",
      "\u001b[39m ---> Using cache\u001b[0m\n",
      "\u001b[39m ---> bb24ae9ca7b8\u001b[0m\n",
      "\u001b[39mStep 13/15 : RUN chmod +x /usr/local/bin/docker-entrypoint.sh\u001b[0m\n",
      "\u001b[39m ---> Using cache\u001b[0m\n",
      "\u001b[39m ---> 6ee34cee3104\u001b[0m\n",
      "\u001b[39mStep 14/15 : ENTRYPOINT [ \"docker-entrypoint.sh\" ]\u001b[0m\n",
      "\u001b[39m ---> Using cache\u001b[0m\n",
      "\u001b[39m ---> b4f93fd2ecd5\u001b[0m\n",
      "\u001b[39mStep 15/15 : CMD [\"bentoml\", \"serve-gunicorn\", \"/bento\"]\u001b[0m\n",
      "\u001b[39m ---> Using cache\u001b[0m\n",
      "\u001b[39m ---> cb1c1ea4a596\u001b[0m\n",
      "\u001b[39mSuccessfully built cb1c1ea4a596\u001b[0m\n",
      "\u001b[39mSuccessfully tagged fashionmnisttensorflow:latest\u001b[0m\n",
      "\u001b[32mFinished building fashionmnisttensorflow:latest from FashionMnistTensorflow:latest\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!bentoml containerize FashionMnistTensorflow:latest -t fashionmnisttensorflow:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-09-22 18:56:21,412] INFO - Starting BentoML API server in production mode..\n",
      "[2020-09-22 18:56:21,638] INFO - Running micro batch service on :5000\n",
      "[2020-09-22 18:56:21 +0000] [12] [INFO] Starting gunicorn 20.0.4\n",
      "[2020-09-22 18:56:21 +0000] [1] [INFO] Starting gunicorn 20.0.4\n",
      "[2020-09-22 18:56:21 +0000] [12] [INFO] Listening at: http://0.0.0.0:5000 (12)\n",
      "[2020-09-22 18:56:21 +0000] [12] [INFO] Using worker: aiohttp.worker.GunicornWebWorker\n",
      "[2020-09-22 18:56:21 +0000] [1] [INFO] Listening at: http://0.0.0.0:54525 (1)\n",
      "[2020-09-22 18:56:21 +0000] [1] [INFO] Using worker: sync\n",
      "[2020-09-22 18:56:21 +0000] [13] [INFO] Booting worker with pid: 13\n",
      "[2020-09-22 18:56:21 +0000] [14] [INFO] Booting worker with pid: 14\n",
      "[2020-09-22 18:56:21,663] WARNING - Using BentoML not from official PyPI release. In order to find the same version of BentoML when deploying your BentoService, you must set the 'core/bentoml_deploy_version' config to a http/git location of your BentoML fork, e.g.: 'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
      "[2020-09-22 18:56:21,681] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.9.0.pre, but loading from BentoML version 0.9.0.pre+7.g8af1c8b\n",
      "[2020-09-22 18:56:21,681] WARNING - Saved BentoService Python version mismatch: loading BentoService bundle created with Python version 3.6.10, but current environment version is 3.6.12.\n",
      "[2020-09-22 18:56:21,687] INFO - Micro batch enabled for API `predict`\n",
      "[2020-09-22 18:56:21,687] INFO - Your system nofile limit is 1048576, which means each instance of microbatch service is able to hold this number of connections at same time. You can increase the number of file descriptors for the server process, or launch more microbatch instances to accept more concurrent connection.\n",
      "[2020-09-22 18:56:31,658] WARNING - Using BentoML not from official PyPI release. In order to find the same version of BentoML when deploying your BentoService, you must set the 'core/bentoml_deploy_version' config to a http/git location of your BentoML fork, e.g.: 'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
      "[2020-09-22 18:56:31,677] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.9.0.pre, but loading from BentoML version 0.9.0.pre+7.g8af1c8b\n",
      "[2020-09-22 18:56:31,677] WARNING - Saved BentoService Python version mismatch: loading BentoService bundle created with Python version 3.6.10, but current environment version is 3.6.12.\n",
      "2020-09-22 18:56:32.844796: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-09-22 18:56:32.868976: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2699905000 Hz\n",
      "2020-09-22 18:56:32.869266: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5640c61366b0 executing computations on platform Host. Devices:\n",
      "2020-09-22 18:56:32.869287: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2020-09-22 18:56:32.946227: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "[2020-09-22 18:56:33,040] WARNING - Importing SavedModels from TensorFlow 1.x.\n",
      "                `outputs = imported(inputs)` is not supported in bento service due to\n",
      "                tensorflow API.\n",
      "\n",
      "                Recommended usage:\n",
      "\n",
      "                ```python\n",
      "                from tensorflow.python.saved_model import signature_constants\n",
      "\n",
      "                imported = tf.saved_model.load(path_to_v1_saved_model)\n",
      "                wrapped_function = imported.signatures[\n",
      "                    signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
      "                wrapped_function(tf.ones([]))\n",
      "                ```\n",
      "\n",
      "                See https://www.tensorflow.org/api_docs/python/tf/saved_model/load for\n",
      "                details.\n",
      "                \n",
      "[2020-09-22 18:56:33,042] WARNING - pip package requirement tensorflow already exist\n",
      "[2020-09-22 18:56:39,213] INFO - {'service_name': 'FashionMnistTensorflow', 'service_version': '20200923023648_D5975E', 'api': 'predict', 'task': {'data': '{\"inputs\":{},\"instances\":[{\"b64\":\"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAYAAAByDd+UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAA2dJREFUSIntlk9L60oYh59Mp43axJoiVj2KboSuXPoJXLkQ/Fx+Ahe6ceFG3CtdWlFcFf9RKlhFatpSbWuaNLHJnIW3OR7ugcu9BzxccGAgZCbv887v/b1JNKWU4hOH+EzYF/AL+OeBYRjysct83wegUqn8HlApRRRFADw+PrK/v4/jOCQSCTRNi/fpug7AwcHB7wEBhHh/9Pj4mGKxyM7Ozt/2NBoNdnd3MU0zvif/CywMQ6SUnJ+fc3NzQy6Xo1KpsLGxgWVZ9Pt9FhYWaLVadLtd5ubmfiT6b2FRFCGlxHEc9vf3UUrR7/d5fX1FKRXPq6srpJRYlsVgMPhn4LD4URTF12EYxlJubW2Ry+WYnp7G8zz6/T65XC6uYzqdRtd1fN+n2+3iOM6vgcPgw+ILIdA0jTAMSSQSAOzt7WHbNtPT0xiGQbvdJpvNMjU1RTKZJAxD3t7e4ni9Xo/b29tfA4egKIoYDAZxAkPYzs4OpVKJ+fl5Wq0W7XYbz/PIZDK8vr6iaRpjY2Mkk0mUUnG8w8ND4INphjbXNA2lFEKIWD6AWq3GwcEBnuextLSE4zj4vk+r1SKVSqFpGq7rxsnpuo4QgnQ6jRCCYrH4DhxK9TH4MKtms0m1WqVcLvP09EQqlWJ8fJx2u0232+Xt7Q3f9xFCUK1WGQwGTExMkEwmEUKglGJ0dJQwDDEMg8vLS+RQqnq9zv39Pb1ej16vh+d53N3d4bouUkpM0ySKIjqdDp7nIaXEdV1GR0fRdZ0gCJidnaXT6eC6LpZl4TgOLy8vpNNpbNvm+fn5XdJCoUCtVkNKSbPZjA0yBDmOg23bKKXwfR/LsoiiCMdxCMOQdDqNYRhkMhkajUaslGVZCCHwPI8gCJBSIo+Ojtje3iafzzMzMxOfJJVKxe9G0zQJggAhRNxvnuehaRpRFGHbNvV6nevra4IgIAxDAAzDwHVddF3HMAympqaQKysrnJ6ecnFx8aOwf50sm82SzWbJZDIEQYBSilarRblcxnVdut0umqZRKpVYXl5mcXGRQqGA7/uxD6SUfPv2DdM031388SfKcRzOzs4ol8ucnJzQbDZ/atqhA7PZLPl8ntXVVdbW1hgZGYnX19fXeXh4YHJyEtM0MU0TKSW6rrO5ufkz8DPG//sD/AX8I8DvdgnOxdB4B1wAAAAASUVORK5CYII=\"}],\"signature_name\":\"string\"}', 'task_id': 'afad2987-0493-4319-97f3-b2f44525a258', 'batch': 1, 'http_headers': (('Host', '192.168.101.102:5000'), ('Connection', 'keep-alive'), ('Content-Length', '1352'), ('accept', '*/*'), ('DNT', '1'), ('User-Agent', 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.102 Safari/537.36'), ('Content-Type', 'application/json'), ('Origin', 'http://192.168.101.102:5000'), ('Referer', 'http://192.168.101.102:5000/'), ('Accept-Encoding', 'gzip, deflate'), ('Accept-Language', 'en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7'), ('Cookie', '_xsrf=2|576ad55d|3635bb714e41d7ee3700400128996fb4|1600795330; username-192-168-101-102-8889=\"2|1:0|10:1600795338|29:username-192-168-101-102-8889|44:ZDA5NWI2OGYzYzBhNGUzNmIyZjc5NDMyMDdmMDEyNDE=|97dc14247a423d47f2a96b759f90255cebac8e7b19d2bb53fb3f53ac8858bde3\"'))}, 'result': {'data': '[\"Ankle boot\"]', 'http_status': 200, 'http_headers': (('Content-Type', 'application/json'),)}, 'request_id': 'afad2987-0493-4319-97f3-b2f44525a258'}\n",
      "^C\n",
      "[2020-09-22 18:57:22 +0000] [1] [INFO] Handling signal: int\n",
      "[2020-09-22 18:57:22 +0000] [13] [INFO] Worker exiting (pid: 13)\n"
     ]
    }
   ],
   "source": [
    "!docker run -p 5000:5000 fashionmnisttensorflow:latest --workers 1 --enable-microbatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy BentoService as REST API server to the cloud\n",
    "\n",
    "\n",
    "BentoML support deployment to multiply cloud provider services, such as AWS Lambda, AWS Sagemaker, Google Cloudrun and etc. You can find the full list and guide on the documentation site at https://docs.bentoml.org/en/latest/deployment/index.html\n",
    "\n",
    "For this demo, we are going to deploy to AWS Sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bento_service_tag = f'{bento_svc.name}:{bento_svc.version}'\n",
    "print(bento_service_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml sagemaker deploy first-tf-fashion -b {bento_service_tag} --api-name predict --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml sagemaker get first-tf-fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws sagemaker-runtime invoke-endpoint --endpoint-name dev-first-tf-fashion --content-type 'application/json' \\\n",
    "--body \"{\\\"instances\\\":[{\\\"b64\\\":\\\"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAYAAAByDd+UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAA2dJREFUSIntlk9L60oYh59Mp43axJoiVj2KboSuXPoJXLkQ/Fx+Ahe6ceFG3CtdWlFcFf9RKlhFatpSbWuaNLHJnIW3OR7ugcu9BzxccGAgZCbv887v/b1JNKWU4hOH+EzYF/AL+OeBYRjysct83wegUqn8HlApRRRFADw+PrK/v4/jOCQSCTRNi/fpug7AwcHB7wEBhHh/9Pj4mGKxyM7Ozt/2NBoNdnd3MU0zvif/CywMQ6SUnJ+fc3NzQy6Xo1KpsLGxgWVZ9Pt9FhYWaLVadLtd5ubmfiT6b2FRFCGlxHEc9vf3UUrR7/d5fX1FKRXPq6srpJRYlsVgMPhn4LD4URTF12EYxlJubW2Ry+WYnp7G8zz6/T65XC6uYzqdRtd1fN+n2+3iOM6vgcPgw+ILIdA0jTAMSSQSAOzt7WHbNtPT0xiGQbvdJpvNMjU1RTKZJAxD3t7e4ni9Xo/b29tfA4egKIoYDAZxAkPYzs4OpVKJ+fl5Wq0W7XYbz/PIZDK8vr6iaRpjY2Mkk0mUUnG8w8ND4INphjbXNA2lFEKIWD6AWq3GwcEBnuextLSE4zj4vk+r1SKVSqFpGq7rxsnpuo4QgnQ6jRCCYrH4DhxK9TH4MKtms0m1WqVcLvP09EQqlWJ8fJx2u0232+Xt7Q3f9xFCUK1WGQwGTExMkEwmEUKglGJ0dJQwDDEMg8vLS+RQqnq9zv39Pb1ej16vh+d53N3d4bouUkpM0ySKIjqdDp7nIaXEdV1GR0fRdZ0gCJidnaXT6eC6LpZl4TgOLy8vpNNpbNvm+fn5XdJCoUCtVkNKSbPZjA0yBDmOg23bKKXwfR/LsoiiCMdxCMOQdDqNYRhkMhkajUaslGVZCCHwPI8gCJBSIo+Ojtje3iafzzMzMxOfJJVKxe9G0zQJggAhRNxvnuehaRpRFGHbNvV6nevra4IgIAxDAAzDwHVddF3HMAympqaQKysrnJ6ecnFx8aOwf50sm82SzWbJZDIEQYBSilarRblcxnVdut0umqZRKpVYXl5mcXGRQqGA7/uxD6SUfPv2DdM031388SfKcRzOzs4ol8ucnJzQbDZ/atqhA7PZLPl8ntXVVdbW1hgZGYnX19fXeXh4YHJyEtM0MU0TKSW6rrO5ufkz8DPG//sD/AX8I8DvdgnOxdB4B1wAAAAASUVORK5CYII=\\\"}]}\" \\\n",
    "output.json && cat output.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml sagemaker delete first-tf-fashion --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "classification.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "bentoml-py36-tf114",
   "language": "python",
   "name": "bentoml-py36-tf114"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
